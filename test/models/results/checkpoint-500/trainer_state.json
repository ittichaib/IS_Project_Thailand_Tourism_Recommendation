{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8460236886632826,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 4.481597423553467,
      "learning_rate": 4.971799210377891e-05,
      "loss": 0.6669,
      "step": 10
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 7.331534385681152,
      "learning_rate": 4.943598420755781e-05,
      "loss": 0.6834,
      "step": 20
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 3.0499420166015625,
      "learning_rate": 4.9153976311336716e-05,
      "loss": 0.5472,
      "step": 30
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 2.4408702850341797,
      "learning_rate": 4.887196841511563e-05,
      "loss": 0.5009,
      "step": 40
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 2.4503562450408936,
      "learning_rate": 4.8589960518894536e-05,
      "loss": 0.6766,
      "step": 50
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 2.340404748916626,
      "learning_rate": 4.8307952622673436e-05,
      "loss": 0.3811,
      "step": 60
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 3.4495749473571777,
      "learning_rate": 4.802594472645234e-05,
      "loss": 0.4524,
      "step": 70
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 5.7749857902526855,
      "learning_rate": 4.774393683023125e-05,
      "loss": 0.586,
      "step": 80
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 4.181771278381348,
      "learning_rate": 4.746192893401015e-05,
      "loss": 0.4455,
      "step": 90
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 13.942787170410156,
      "learning_rate": 4.717992103778906e-05,
      "loss": 0.4146,
      "step": 100
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 5.111000061035156,
      "learning_rate": 4.689791314156797e-05,
      "loss": 0.729,
      "step": 110
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 4.466853141784668,
      "learning_rate": 4.661590524534687e-05,
      "loss": 0.5406,
      "step": 120
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 2.4808173179626465,
      "learning_rate": 4.633389734912578e-05,
      "loss": 0.4424,
      "step": 130
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 2.6466658115386963,
      "learning_rate": 4.6051889452904683e-05,
      "loss": 0.6466,
      "step": 140
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 4.443167209625244,
      "learning_rate": 4.576988155668359e-05,
      "loss": 0.5435,
      "step": 150
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 4.090594291687012,
      "learning_rate": 4.548787366046249e-05,
      "loss": 0.4578,
      "step": 160
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 15.050884246826172,
      "learning_rate": 4.5205865764241404e-05,
      "loss": 0.4161,
      "step": 170
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 5.0694260597229,
      "learning_rate": 4.492385786802031e-05,
      "loss": 0.3778,
      "step": 180
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 13.483394622802734,
      "learning_rate": 4.464184997179921e-05,
      "loss": 0.452,
      "step": 190
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 5.629690647125244,
      "learning_rate": 4.435984207557812e-05,
      "loss": 0.4247,
      "step": 200
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 6.419111251831055,
      "learning_rate": 4.4077834179357024e-05,
      "loss": 0.4914,
      "step": 210
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 3.732213020324707,
      "learning_rate": 4.379582628313593e-05,
      "loss": 0.5224,
      "step": 220
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 5.3917036056518555,
      "learning_rate": 4.351381838691484e-05,
      "loss": 0.3372,
      "step": 230
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 3.4324309825897217,
      "learning_rate": 4.3231810490693744e-05,
      "loss": 0.4801,
      "step": 240
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 3.5091776847839355,
      "learning_rate": 4.294980259447265e-05,
      "loss": 0.4777,
      "step": 250
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 6.67073917388916,
      "learning_rate": 4.266779469825155e-05,
      "loss": 0.4955,
      "step": 260
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 3.357159376144409,
      "learning_rate": 4.238578680203046e-05,
      "loss": 0.2592,
      "step": 270
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 3.9648048877716064,
      "learning_rate": 4.2103778905809365e-05,
      "loss": 0.5106,
      "step": 280
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 2.1220855712890625,
      "learning_rate": 4.182177100958827e-05,
      "loss": 0.3965,
      "step": 290
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 9.42971134185791,
      "learning_rate": 4.153976311336718e-05,
      "loss": 0.564,
      "step": 300
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 8.887862205505371,
      "learning_rate": 4.1257755217146085e-05,
      "loss": 0.402,
      "step": 310
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 8.343894958496094,
      "learning_rate": 4.097574732092499e-05,
      "loss": 0.4607,
      "step": 320
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 8.829174995422363,
      "learning_rate": 4.069373942470389e-05,
      "loss": 0.2664,
      "step": 330
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 0.8774228096008301,
      "learning_rate": 4.04117315284828e-05,
      "loss": 0.3579,
      "step": 340
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 11.975106239318848,
      "learning_rate": 4.0129723632261705e-05,
      "loss": 0.4252,
      "step": 350
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 9.686868667602539,
      "learning_rate": 3.9847715736040605e-05,
      "loss": 0.6306,
      "step": 360
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 2.9791419506073,
      "learning_rate": 3.956570783981952e-05,
      "loss": 0.4678,
      "step": 370
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 7.131058216094971,
      "learning_rate": 3.9283699943598425e-05,
      "loss": 0.4637,
      "step": 380
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 4.465388298034668,
      "learning_rate": 3.900169204737733e-05,
      "loss": 0.4211,
      "step": 390
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 8.510282516479492,
      "learning_rate": 3.871968415115623e-05,
      "loss": 0.449,
      "step": 400
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 4.25584077835083,
      "learning_rate": 3.843767625493514e-05,
      "loss": 0.5922,
      "step": 410
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 5.292862415313721,
      "learning_rate": 3.8155668358714046e-05,
      "loss": 0.4138,
      "step": 420
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 6.027608871459961,
      "learning_rate": 3.787366046249295e-05,
      "loss": 0.4886,
      "step": 430
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 2.8452389240264893,
      "learning_rate": 3.759165256627186e-05,
      "loss": 0.4093,
      "step": 440
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 7.819489002227783,
      "learning_rate": 3.7309644670050766e-05,
      "loss": 0.5836,
      "step": 450
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 5.0829315185546875,
      "learning_rate": 3.702763677382967e-05,
      "loss": 0.39,
      "step": 460
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 4.721904277801514,
      "learning_rate": 3.674562887760857e-05,
      "loss": 0.3647,
      "step": 470
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 5.13138484954834,
      "learning_rate": 3.646362098138748e-05,
      "loss": 0.5349,
      "step": 480
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 12.826119422912598,
      "learning_rate": 3.6181613085166386e-05,
      "loss": 0.4356,
      "step": 490
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 5.266170024871826,
      "learning_rate": 3.589960518894529e-05,
      "loss": 0.4692,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1773,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 263118142464000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
